grouped_matmul_v4:
  description: |
    Group calculation matmul.

    ** Non-Quant: **

    .. math::
            y_i = x_i\times weight_i + bias_i

    ** Antiquant-Quant: **

    .. math::
            y_i = x_i\times (weight_i + antiquant\_offset_i) * antiquant\_scale_i + bias_i

    .. note::
        - Only when `bias` , `scale` , `offset` , `antiquant_scale` and `antiquant_offset` are all None, `group_type` is 0,
          and `split_item` is 3, the reverse derivative is supported.
        - When `x` type is int8 and `weight` type is int4, the `scale` should be of the uint64 data type,
          but its memory needs to be arranged in float32 format.
        
    ** Per-Token-Quant **
    
    .. math::
             y_i = (x_i\times weight_i + bias_i) * scale_i * per\_token\_scale_i

    Args:
        x (TensorList): The input tensor list, include 2D-6D Tensors. Supported dtypes: Float16, Float32, Int8.
                        The shape of the tensor in tensorlist is :math:`(M, K)` or :math:`(..., M, K)`.
        weight (TensorList): The weight tensor list, include 2D-3D Tensors. Supported dtypes: Float16, Float32, Int8.
                             The shape of the tensor in tensorlist is :math:`(K, N)` or :math:`(E, K, N)`.
        bias (TensorList, optional): The list of bias tensors in matrix multiplication, include 1D-2D Tensors.
                                     Supported dtypes: Float16, Float32, Int32. Default: ``None``.
                                     Length is the same as the weight length. The shape of the tensor is :math:`(N)` or :math:`(E, N)`.
        scale (TensorList, optional): Scale factors of quant(A8W8) parameters. Supported dtypes: BFloat16.
                                      Length is the same as the weight length. The shape of the tensor is :math:`(N)` or :math:`(E, N)`.
        offset (TensorList, optional): Offset factors of quant(A8W8) parameters. Supported dtypes: Float32.
                                       Length is the same as the weight length. Currently not supported. Default: ``None``.
        antiquant_scale (TensorList, optional): Scale factors of antiquant(A16W8) parameters. Supported dtypes: Float16.
                                                Length is the same as the weight length. The shape of the tensor is :math:`(N)` or
                                                :math:`(E, N)`. Only use in antiquant. Default: ``None``.
        antiquant_offset (TensorList, optional): Offset factors of antiquant(A16W8) parameters. Supported dtypes: Float16.
                                                 Length is the same as the weight length. The shape of the tensor is :math:`(N)` or
                                                 :math:`(E, N)`. Only use in antiquant. Default: ``None``.
        pre_token_scale (TensorList, optional): Per-token quant parameters, include 1D Tensors. Supported dtypes: Float32.
                                                Length is the same as the x length. The shape of the tensor is :math:`(M)`.
                                                Only use in per-token quant. Default: ``None``.
        group_list (Tensor, optional): Grouping positions for the M-axis of input x. Supported dtypes: Int64. Default: ``None``.
        activation_input (TensorList, optional): Inputs of actiation function. Currently not supported. Default: ``None``.
        activation_quant_scale (TensorList, optional): Scale factors of activation. Currently not supported. Default: ``None``.
        activation_quant_offset (TensorList, optional): Offset factors of activation. Currently not supported. Default: ``None``.
        split_item (int): Splitting input mode. Only support 0 and 3. 0 represents multiple Tensors, and 3 represents a single Tensor.
                          Default: ``0``.
        group_type (int): The axis to be split. Only support -1 and 0. If the matrix is multiplied by A[m,k]xB[k,n]=C[m,n].
                          -1: No grouping, 0: Group on the m-axis. Default: ``-1``.
        group_list_type (int): The format type of grouping positions. Only support 0 and 1. 0 represents the grouping positions
                               as the cumsum of grouping size in each group, and 1 represents the positions as the grouping size in
                               each group. Default: ``0``.
        act_type (int): Activation function type. Currently not supported. Default: ``0``.
        output_dtype (mindspore.dtype): Specifies the output data type, currently taking effect only when input x is int8 and weight is int4.
                                        If None is passed in, bfloat16 will be used by default. Default: ``None``.


        Parameter limitations 1
        =========== ============ =========== ====================================================================================================
        split_item  group_type   group_list  notes
        =========== ============ =========== ====================================================================================================
        0           -1           None        The length of x is n, tensor in x must be 2D-6D. The length of weight is n, tensor in weight must be 2D.
                                             The length of all TensorList inputs must be the same.
        3           0            1D Tensor   The length of x is 1, tensor in x must be 2D. The length of weight is 1, tensor in weight must be 3D.
                                             (group_list.shape)[0] must be equal to (weight.shape)[0], and its numbers must be positive
                                             (increasing when group_list_type is 0).
                                             The sum of group_list (last number when group_list_type is 0) can be less equal than length of x.
        =========== ============ =========== ====================================================================================================

        Parameter limitations 2
        Non-quant type table
        =========   =========  ============  =========  =========  ================  =================  ===============  =========
        x           weight     bias          scale      offset     antiquant_scale   antiquant_offset   pre_token_scale  y
        =========   =========  ============  =========  =========  ================  =================  ===============  =========
        Float16     Float16    Float16/None  None       None       None              None               None             Float16
        =========   =========  ============  =========  =========  ================  =================  ===============  =========
        BFloat16    BFloat16   Float32/None  None       None       None              None               None             BFloat16
        =========   =========  ============  =========  =========  ================  =================  ===============  =========

        Parameter limitations 3
        Only in split_item=3, group_type=0
        =========   =========  ============  =========  =========  ================  =================  ===============   =========
        x           weight     bias          scale      offset     antiquant_scale   antiquant_offset   pre_token_scale   y
        =========   =========  ============  =========  =========  ================  =================  ===============   =========
        Float32     Float32    Float32/None  None       None       None              None               None              Float32
        =========   =========  ============  =========  =========  ================  =================  ===============   =========
        
        Parameter limitations 4
        Anti-quant
        The antiquant_scale and antiquant_offset must be used in the same time.
        =========   =========  ============  =========  =========  ================  =================  ===============  =========
        x           weight     bias          scale      offset     antiquant_scale   antiquant_offset   pre_token_scale  y
        =========   =========  ============  =========  =========  ================  =================  ===============  =========
        Float16     Int8       Float16/None  None       None       Float16           Float16            None             Float16
        =========   =========  ============  =========  =========  ================  =================  ===============  ========
        BFloat16    Int8       Float32/None  None       None       BFloat16          BFloat16           None             BFloat16
        =========   =========  ============  =========  =========  ================  =================  ===============  =========
        
        Parameter limitations 4
        Per-token-quant
        The scale and pre_token_scale must be used in the same time.
        =========   =========  ==========  =========  =========  ================  =================  ===============  =========
        x           weight     bias        scale      offset     antiquant_scale   antiquant_offset   pre_token_scale  y
        =========   =========  ==========  =========  =========  ================  =================  ===============  =========
        Int8        Int8       int32/None  BFloat16   None       None              None               Float32          BFloat16
        =========   =========  ==========  =========  =========  ================  =================  ===============  =========

    Returns:
        TensorList, include 2D Tensors. The shape of the tensor is :math:`(M, N)`.

    Raises:
        TypeError: If `split_item` is not 0 or 3.
        TypeError: If `group_type` is not -1 or 0.
        TypeError: If `group_list_type` is not 0 or 1.
        TypeError: when `split_item` is 0, `group_type` is not -1.
        TypeError: when `split_item` is 3, `group_type` is not 0.
        TypeError: when `split_item` is 3, `group_list` is None.

    Supported Platforms:
        ``Ascend``

    Examples:
        >>> import mindspore as ms
        >>> import numpy as np
        >>> from mindspore import nn, context
        >>> from mindspore.ops.auto_generate import grouped_matmul_v4
        >>> ms.set_device(device_target="Ascend")
        >>> context.set_context(mode=ms.GRAPH_MODE)
        >>> x = [ms.Tensor(np.array([[0, 0, 0, 0],
        ...                          [1, 1, 1, 1],
        ...                          [2, 2, 2, 2],
        ...                          [2, 2, 2, 2],
        ...                          [1, 1, 1, 1],
        ...                          [1, 1, 1, 1]]), ms.float16)]
        >>> weight = [ms.Tensor(np.arange(32).reshape((4, 4, 2)), ms.float16)]
        >>> group_list = ms.Tensor([1, 2, 1, 2], ms.int64)
        >>> output = grouped_matmul_v4(x, weight, group_list=group_list, split_item=3, group_type=0, group_list_type=1)
        >>> print(output[0])
        [[0   0  ]
         [44  48 ]
         [88  96 ]
         [152 160]
         [108 112]
         [108 112]]
